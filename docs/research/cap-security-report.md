Capability-Based Security: JWT vs Internal Tokens

Capability-based security grants access through possession of unforgeable tokens that encode permissions for specific resources or actions, rather than by identity alone . In this model each “capability” (token) carries just the rights it confers. For example, like a UNIX file descriptor that includes a reference and allowed operations, a capability token embodies both the what (resource) and the how (permitted operations) . This enables fine-grained, least-privilege design: a token can be restricted to only the necessary rights and can be delegated (shared) or attenuated without revealing other privileges . Unlike broad identity-based permissions, a holder of a capability can only access what is granted by that token. Capability models have been used in operating systems and distributed systems (e.g. Cosmos SDK modules use an object-capability model, where modules only gain access if explicitly passed the capability reference ).

In our architecture, we use JWTs (JSON Web Tokens) as a standard external interop format (for example, OAuth2 access tokens or OpenID Connect ID tokens) and separate internal capability tokens (possibly using formats like Macaroons, Biscuit, or custom opaque tokens) for intra-system calls. In general, JWTs serve as a cross-system “identity” or session token (signed and possibly encrypted), while internal tokens strictly encode the minimal permissions needed by an agent or service. We must clearly delineate these roles to minimize attack surface: treat any external-facing JWT as a bearer token (like a $20 bill)  and do not expose internal capability tokens beyond our secure boundaries. We rely entirely on well-tested libraries (Rust crates and standard protocols) for all cryptography and token handling, avoiding any homegrown primitives. This ensures secure defaults, auditability, and future-proofing.

JWT as Interop Layer

Use-case and Properties: JWTs are a standard, compact, URL-safe token format (RFC 7519) widely used in OAuth2/OpenID Connect for conveying identity and authorization claims . They are “by-value” (contain their own data) and can be signed (JWS) or encrypted (JWE). In our system, JWTs are used primarily at the boundary or between service boundaries: for example, the agent runtime might authenticate users or services using OAuth2 flows that yield JWT access or ID tokens. These tokens include claims like issuer (iss), audience (aud), subject (sub), scopes or permissions, and expiration (exp) and are validated by the recipient without a central lookup (by verifying the signature and claims).

Best Practices: To use JWT safely, follow community standards :
	•	Validate Signatures and Algorithms: Always verify the signature using a vetted library (e.g. the jsonwebtoken crate in Rust  or josekit). Never accept tokens with alg: "none". As Curity notes, one must strictly check the JWT header’s alg against an allow-list of secure algorithms to avoid downgrade attacks (even case-sensitive variants of “none” can be maliciously accepted) . Use modern algorithms: EdDSA (Ed25519) is highly recommended for security and performance , or ECDSA (ES256) if broad compatibility is needed. Maintain an allow-list (not a deny-list) of algorithms and reject any token with an unexpected alg .
	•	Check Issuer and Audience: Always ensure the iss (issuer) and aud (audience) claims exactly match expected values  . For example, if tokens should come from https://auth.example.com, do not accept one claiming https://auth.example.com/secure . Likewise, verify the aud claim contains the intended recipient (e.g. your service’s own identifier). This prevents using a token meant for one API on another by mistake .
	•	Use Appropriate Token Types: Distinguish ID tokens vs access tokens. A resource server should refuse an ID token used as an access token . You can do this by checking the typ header or a custom purpose claim (e.g. “access_token” vs “id_token”), or by ensuring access tokens contain scopes whereas ID tokens do not .
	•	Limit Token Contents: Since JWTs are readable by any holder, avoid embedding sensitive data. Do not put PII or secrets in a client-facing token. Curity recommends removing private data from JWTs or using alternative patterns (e.g. opaque “phantom” tokens with JWTs only inside your infrastructure) . In short, any data in the JWT header or payload should not help attackers (e.g. don’t reveal internal technology stack details) .
	•	Short Lifetimes: Because JWTs cannot be easily revoked once issued, keep their TTL as short as practical. Best practice is minutes or hours, not days or longer . Include the exp claim and enforce it. Also consider nbf (“not before”) to prevent premature use . Allow a few seconds of clock skew for distributed systems, but avoid large skews .
	•	Key Management: Use established libraries and standards for key storage and rotation. For example, use JSON Web Key (JWK) sets (via HTTPS discovery) if supporting multiple issuers. Ensure that the public keys used to verify JWTs are actually tied to the claimed issuer . In Rust, you can use crates like jsonwebtoken (which internally supports loading keys from PEM/der or JWKS) .

When issuing JWTs, use standard libraries (e.g. jsonwebtoken or josekit) and strong randomness (Rust’s rand or ring). Never implement cryptography by hand. For example, the jsonwebtoken crate supports HMAC, RSA, PS (RSA-PSS), ECDSA, and EdDSA algorithms , covering modern needs. This crate (like others) uses tried-and-true crypto under the hood, so we focus on correct usage rather than re-creating primitives.

Internal Capability Tokens

Within our agent runtime, we use internal tokens that embody specific capabilities or rights, distinct from the more identity-focused JWTs. These tokens are not exposed externally; they are consumed only by trusted components in our system. Several approaches are possible:
	•	Minting Internal JWTs: We could still use JWT format internally, but with an isolated key and minimal claims. For example, when an agent is granted the right to perform an action, we issue a signed JWT with only the necessary claim (e.g. {"action":"read_file","file_id":123}) and a short expiry. This token is only valid within our system and is verified by internal services against our internal signing key. We should segregate keys: e.g. a dedicated key for internal tokens that is never published externally. The same JWT validation best practices apply (check signature, issuer, expiration, etc). Because these tokens are for short-lived internal use, we might allow slightly longer lifetimes than user tokens, but still aim for minimal durations.
	•	Opaque Tokens + Introspection: Alternatively, internal tokens may be opaque identifiers (e.g. UUIDs) stored in a secure database or token store. In this model, the “token” is simply a random string, and services use an introspection-like call (backed by our database) to retrieve the associated capabilities. This lets us revoke tokens immediately by deleting them from the store. The downside is the need for a database lookup on each request. If we go this route, we can adopt an OAuth2-style introspection endpoint (RFC 7662) internally: a protected HTTP endpoint (or internal RPC) that, given a token, returns whether it’s active and what rights it has  . For example, the response might be {"active":true,"actions":["read_file","list_dir"],"expires":1670000000}. The endpoint must be secured (e.g. only callable from inside the cluster) so untrusted clients can’t query it .
	•	Macaroons: Macaroons (Google’s invention) are flexible bearer tokens with built-in “caveats” (restrictions) that travel with the token . A single macaroon can carry chained restrictions (e.g. valid only until a time, or only on certain resource), and holders can attenuate a macaroon by adding more caveats (making it only more restrictive) . This fits capability semantics well: the original issuer creates a macaroon with broad rights, and each delegate can bake in extra conditions before passing it on. Macaroons are HMAC-signed and verifiable without a central store. Rust crates like macaroon or rust-macaroon implement these. Using macaroons lets us avoid a DB lookup, but we lose simple revocation (except via expiry or a centralized blocklist of signature keys). Lightning Network uses macaroons heavily (e.g. LND’s admin/readonly/invoice macaroons) .
	•	Biscuit Tokens: For very fine-grained, decentralized scenarios, Biscuit tokens embed Datalog logic for policies . A Biscuit token starts with an issuer-signed authority block (listing rights) and can be attenuated by the holder adding logic checks. It supports offline delegation (holders can create new valid tokens by weakening rights, without contacting a server) . In Rust there is the biscuit-auth crate. Biscuit tokens are validated solely with public keys – any node can check them. They do not include built-in revocation (the docs explicitly say revocation requires external state) , so they rely on short expiry or external signals. Biscuit suits microservices where capabilities are complex, but it has a steep learning curve (and involves embedding a logic engine).
	•	Other Libraries: Depending on environment, other Rust crates like ring (for crypto primitives), ed25519-dalek (Ed25519 signatures), or even sodiumoxide (libsodium) may be used under the hood for signing/verification. We should pick crates that support no-std or WASM if needed. For instance, ed25519-dalek is pure Rust and works in WASM; ring is highly optimized. We will not build any elliptic-curve or HMAC code ourselves, only orchestrate existing libraries.

Key Separation: To minimize cross-contamination, we keep cryptographic keys separate. For example, keys used to sign external JWTs (e.g. an RSA or Ed25519 keypair for OAuth tokens) are never used for internal capability tokens. If using JWT format internally, use a different key ID or keypair so that internal JWTs cannot be submitted as external tokens and vice versa. Similarly, if using public-key signatures (as with Biscuit or EdDSA), maintain a root key for authority and rotate keys periodically. The token verification logic must be explicit about which issuer/public key is expected for each token type.

Least Authority in Practice: In the runtime, each component (agent or service) is only given the tokens/capabilities it strictly needs. For example, an agent needing read-only access to a data store gets an internal token restricted to “read” scope on that store. Any attempt to use the token for write will be rejected by the service. If the agent later needs more rights, it must obtain a new token from the authority. This minimizes the blast radius of token theft or misuse.

Secure Defaults and Standards

We adhere to established standards (OAuth2, OIDC, JOSE) and well-reviewed code. We never “roll our own crypto”. For JWT handling we use crates like jsonwebtoken, which implements RFC 7515/7519 and supports modern algorithms . For Macaroons or Biscuit we use their standard Rust libraries, which in turn use HMAC or Ed25519 implementations from proven crates. For all random nonces or IDs, use Rust’s secure RNG (e.g. rand::rngs::OsRng or ring::rand) and for key storage use secure keystores or memory-safe facilities (avoiding secrets in code or logs).

To minimize attack surface:
	•	The code paths that parse tokens are small and use safe deserialization (e.g. Serde) to prevent injection.
	•	We disable any unnecessary algorithms (no deprecated JWT algos).
	•	In WASM environments, the sandbox (WASM’s memory safety) adds protection.
	•	We audit third-party crates for vulnerabilities and pin to specific versions.
	•	Compile with Rust’s security flags (for example -C overflow-checks=on in debug, and use wasm-bindgen wisely).
	•	Logging and introspection endpoints are internal-only and protected behind authentication/authorization.

We also consider future-proofing: By using algorithm-agile libraries (JWS/JWE registries ), we can swap in quantum-resistant schemes later (e.g. Ed448 or post-quantum KEMs) without redesigning the system. Key rotation mechanisms are built-in (JWKS or internal key IDs) so that we can rotate keys when needed. Because tokens are short-lived and validated per standard, even new cryptanalytic threats mostly just require key upgrades, not new protocols.

Token Lifecycle: Introspection and Revocation

Introspection: For opaque or refresh tokens, we provide an introspection endpoint (RFC 7662) on the authorization server . Resource servers (or internal services) call this endpoint to check token validity. For example, a POST with token=<value> returns JSON with "active":true or false, plus metadata like expiration, scopes, client ID, username, etc  . This endpoint is protected (e.g. not publicly accessible) so that only our services or the gateway can introspect . If we use JWTs without an introspection call, services instead validate locally. But for internal opaque tokens, introspection (i.e. a secure lookup) is how we verify and discover the associated capabilities.

Revocation: Because JWTs are stateless, we cannot “revoke” a previously-issued JWT except by making it expire quickly or keeping a revocation list (an anti-pattern if it defeats the point of self-contained tokens). Therefore:
	•	External JWTs: We use short lifetimes (minutes/hours) and rely on those plus transport security (HTTPS) to minimize risk. For user sign-out flows or emergency revocations, we support RFC 7009 revocation: our authorization server offers a /revoke endpoint where a client can present its access or refresh token and have the server invalidate it . Revocation invalidates that token immediately (and may cascade to related tokens) . Internally, we still cannot retroactively revoke the already-issued JWT, but we can refuse to honor the associated refresh token, and we can prune sessions. Clients must not reuse a token after a revoke request . In practice, we also rely on extremely short-lived access tokens and rotate them via refresh tokens, so revocation of a refresh token effectively ends future access.
	•	Internal Tokens: We design them to be short-lived or easily revokeable. If using opaque tokens (random IDs), revocation is simply deleting the entry in our store. If using JWT-like or capabilities (Macaroons/Biscuit), explicit revocation is hard: we rely on TTL expiration. For high-assurance cases, we could maintain a blocklist of token IDs or macaroon identifiers, but this reintroduces state. In many capability designs (e.g. Biscuit) revocation is considered outside-scope . Thus, we emphasize token expiration and re-issuance over manual revocation for internal tokens.

Auditing: We log all token-related events. Token issuances, refreshes, revocations, and introspection checks are logged with timestamp, client ID, and token ID (e.g. the jti claim). This allows post-mortem tracing of which services used which capabilities. For JWTs, include a unique JWT ID (jti) in the claims so you can correlate logs and detect reuse. Audit logs are append-only and monitored for anomalies. If a capability token is overused (e.g. a read-only token suddenly attempts a write), the service should log and alert. Periodic security reviews inspect these logs for unusual patterns.

Deployment Considerations
	•	Distributed Environment: In a microservices deployment, each service runs a Rust/WASM module that trusts only its own configuration and public keys. They fetch or are configured with the authorization server’s public key (or JWKS URL) to validate JWTs. They also know how to call the internal introspection endpoint. We minimize inter-service trust by having each service check tokens itself; no service blindly trusts another without verification. For WASM modules running in untrusted hosts, we make sure no secret keys are embedded – keys are kept on the host or a secure enclave, not in the WASM. Calls into the WASM (e.g. through WebAssembly System Interface or host functions) should be guarded by validating incoming tokens first.
	•	Rust and WASM: Rust’s strong type system and ownership model prevents many vulnerabilities out of the box. When compiling to WASM (e.g. via Wasm-bindgen or WASI), we still use the same crates for JWT or Macaroons (they often support no_std or were tested on WASM). We should be cautious that some crypto crates (like ring) may or may not have full WASM support; if not, use pure-Rust alternatives (e.g. ed25519-dalek). In very resource-constrained environments, we might use symmetric HMAC (HS256) for speed, but public-key (RS256/ES256/EdDSA) provides better security for inter-service tokens without sharing a global secret.
	•	Extensibility: Our design anticipates future needs. For example, if in 5–10 years new identity federation protocols emerge, they can still issue JWTs to our gateway which we validate per the above rules. If new crypto standards arise, we update library dependencies. Because we separate concerns (authentication vs capability), we can replace or augment the system (e.g. plug in Verifiable Credentials or ZK proof tokens) without rewriting the core.

Summary

In summary, we clearly divide roles: use JWTs (with jsonwebtoken or similar libraries) strictly as an interoperability token format (subject to standard validation, short lifetimes, no sensitive data)  . For internal agent-to-service calls, use dedicated capability tokens (e.g. JWTs with limited claims, Macaroons, or Biscuit) that encode only what is needed. All tokens are signed with well-known algorithms (Ed25519 or ECDSA preferred) using audited crypto crates. Services always validate tokens (signature, issuer, audience, type, expiry) before granting access  . We implement introspection and revocation endpoints per OAuth2 standards (RFCs 7662 and 7009)   and log all token operations for audit. By relying on proven libraries and security-by-default practices, we minimize attack surface and ensure the system remains secure and robust for years to come.

Sources: Industry best practices and standards (OAuth2/OIDC/JWT RFCs) guide these designs    . For example, Curity’s JWT security guide and OAuth Token Introspection spec informed our validation and introspection strategy  , while literature on capability security and Macaroons/Biscuit inspired our internal token approach   .". and rewrite as a clean v 0.1 official spec instead of a draft.