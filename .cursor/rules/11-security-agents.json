{
  "kind": "rule",
  "metadata": {
    "name": "security-agents",
    "version": "2.0.0",
    "title": "SecurityAgents",
    "description": "Security guidelines for AI agents with execution capabilities",
    "tags": [
      "security.base"
    ],
    "priority": "critical",
    "created": "2025-07-07",
    "modified": "2025-07-07T06:32:26.512369+00:00",
    "checksum": "62fe44504e8382ef",
    "schema_version": "2.0.0"
  },
  "spec": {
    "always_apply": false,
    "extends": [],
    "objectives": [
      "Prevent unauthorized or irreversible agent actions",
      "Constrain agents within observable environments",
      "Prevent prompt injection and capability escalation"
    ],
    "guidelines": {
      "agent_constraints": [
        "All agents must declare capabilities explicitly",
        "Disallow dynamic tool access unless authorized",
        "Prefer capability-based over natural language interfaces"
      ],
      "sandboxing": [
        "Run in isolated environments (WASM, Docker, virtual VFS)",
        "Log inputs and outputs deterministically",
        "Enforce timeouts and memory limits"
      ],
      "input_hardening": [
        "Sanitize all user input before LLM forwarding",
        "Detect prompt injection patterns",
        "Use structured schemas for critical actions"
      ]
    }
  }
}